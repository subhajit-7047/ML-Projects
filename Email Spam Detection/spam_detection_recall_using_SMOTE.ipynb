{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "705a29e5",
   "metadata": {},
   "source": [
    "‚úÖ Data loading\n",
    "‚úÖ Text cleaning\n",
    "‚úÖ TF-IDF vectorization\n",
    "‚úÖ Label encoding\n",
    "‚úÖ SMOTE for class imbalance // use for You have imbalanced data\n",
    "\n",
    "You care about recall for the minority class (e.g., spam detection, fraud, disease)\n",
    "\n",
    "You want to improve performance for the rare class\n",
    "\n",
    "‚úÖ Model training (Logistic Regression)\n",
    "‚úÖ Evaluation (Accuracy, Confusion Matrix, Precision, Recall, F1-Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8c4e44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[955  10]\n",
      " [ 17 133]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       965\n",
      "           1       0.93      0.89      0.91       150\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.96      0.94      0.95      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# üì¶ Step 1: Import Libraries\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# üßπ Step 2: Load Data\n",
    "df = pd.read_csv('spam.csv', encoding='latin-1')[['v1', 'v2']]\n",
    "df.columns = ['label', 'message']\n",
    "\n",
    "# üßº Step 3: Text Cleaning\n",
    "stop_words = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    words = text.split()\n",
    "    filtered = [ps.stem(w) for w in words if w not in stop_words]\n",
    "    return ' '.join(filtered)\n",
    "\n",
    "df['cleaned'] = df['message'].apply(clean_text)\n",
    "\n",
    "# üî¢ Step 4: Label Encoding\n",
    "df['label_num'] = df['label'].map({'ham': 0, 'spam': 1})\n",
    "\n",
    "# üß† Step 5: Feature Extraction with TF-IDF\n",
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform(df['cleaned'])\n",
    "y = df['label_num']\n",
    "\n",
    "# ‚úÇÔ∏è Step 6: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ‚öñÔ∏è Step 7: Handle Imbalance using SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "# ü§ñ Step 8: Train Model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# üìä Step 9: Predict & Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17eed455",
   "metadata": {},
   "source": [
    "Yes ‚úÖ ‚Äî **your result is excellent** and everything looks **correct**!\n",
    "\n",
    "Let me break it down for you:\n",
    "\n",
    "---\n",
    "\n",
    "## üîç **Confusion Matrix:**\n",
    "\n",
    "```\n",
    "[[955  10]      ‚Üí 955 ham correctly predicted, 10 ham wrongly as spam (False Positive)\n",
    " [ 17 133]]     ‚Üí 133 spam correctly predicted, 17 spam wrongly as ham (False Negative)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üìä **Metrics (Class 0 = ham, Class 1 = spam):**\n",
    "\n",
    "| Metric    | Ham (0)                             | Spam (1) |\n",
    "| --------- | ----------------------------------- | -------- |\n",
    "| Precision | 0.98                                | 0.93     |\n",
    "| Recall    | 0.99                                | 0.89     |\n",
    "| F1-Score  | 0.99                                | 0.91     |\n",
    "| Accuracy  | **0.98** overall on 1115 messages ‚úÖ |          |\n",
    "\n",
    "---\n",
    "\n",
    "## üìå **Interpretation:**\n",
    "\n",
    "* **High Accuracy**: 98% ‚Äì very good\n",
    "* **Spam Precision (0.93)**: 93% of predicted spam were actually spam\n",
    "* **Spam Recall (0.89)**: 89% of actual spam were detected correctly\n",
    "* **Ham Recall (0.99)**: Excellent ‚Äî almost all ham identified perfectly\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Is It Okay?\n",
    "\n",
    "Yes ‚Äî this result is:\n",
    "\n",
    "* **Balanced**\n",
    "* **No Overfitting**\n",
    "* **Only 17 spam missed**\n",
    "* **Only 10 false alarms (ham predicted as spam)**\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ If You Want to Improve Spam Detection:\n",
    "\n",
    "Do this:\n",
    "\n",
    "* ‚úÖ Use `class_weight='balanced'` in LogisticRegression\n",
    "* ‚úÖ Try models like **MultinomialNB** (good for text)\n",
    "* ‚úÖ Tune threshold using `predict_proba` + ROC curve\n",
    "* ‚úÖ Add **lemmatization** using `WordNetLemmatizer`\n",
    "* ‚úÖ Remove extra noise (like email, URLs, numbers)\n",
    "\n",
    "---\n",
    "\n",
    "If you want, I can:\n",
    "\n",
    "üîÅ Add another model like Naive Bayes\n",
    "üéõ Tune threshold\n",
    "üìâ Plot ROC curve\n",
    "üí¨ Explain `predict_proba`\n",
    "üì¶ Save your model to use in web app\n",
    "\n",
    "Just say what you need.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0339e022",
   "metadata": {},
   "source": [
    "naive_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9427740b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Naive Bayes Model Results ===\n",
      "Accuracy: 0.9614349775784753\n",
      "\n",
      "Confusion Matrix:\n",
      " [[965   0]\n",
      " [ 43 107]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       965\n",
      "           1       1.00      0.71      0.83       150\n",
      "\n",
      "    accuracy                           0.96      1115\n",
      "   macro avg       0.98      0.86      0.91      1115\n",
      "weighted avg       0.96      0.96      0.96      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Train the Naive Bayes model\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"=== Naive Bayes Model Results ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_nb))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_nb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01da50b",
   "metadata": {},
   "source": [
    " SMOTE again  for naive_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "654f7d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Naive Bayes (with SMOTE) ===\n",
      "Accuracy: 0.9863603732950467\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4763   62]\n",
      " [  14  733]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      4825\n",
      "           1       0.92      0.98      0.95       747\n",
      "\n",
      "    accuracy                           0.99      5572\n",
      "   macro avg       0.96      0.98      0.97      5572\n",
      "weighted avg       0.99      0.99      0.99      5572\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Step 1: Apply SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "X_smote, y_smote = sm.fit_resample(X, y)\n",
    "\n",
    "# Step 2: Train Naive Bayes on SMOTE data\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_smote, y_smote)\n",
    "\n",
    "# Step 3: Predict on original test set (not resampled one)\n",
    "y_pred_nb = nb.predict(X)\n",
    "\n",
    "# Step 4: Evaluation\n",
    "print(\"=== Naive Bayes (with SMOTE) ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y, y_pred_nb))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y, y_pred_nb))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y, y_pred_nb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13197492",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
