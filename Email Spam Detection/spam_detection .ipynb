{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1213eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f88b073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    v1                                                 v2 Unnamed: 2  \\\n",
       "0  ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1  ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"spam.csv\", encoding='latin-1') #here encoding is set to latin-1 to handle special characters\n",
    "#encoding='latin-1': ‡¶ï‡¶ø‡¶õ‡ßÅ ‡¶∏‡ßç‡¶™‡ßá‡¶∂‡¶æ‡¶≤ ‡¶ï‡ßç‡¶Ø‡¶æ‡¶∞‡ßá‡¶ï‡ßç‡¶ü‡¶æ‡¶∞ ‡¶¨‡¶æ ‡¶á‡¶â‡¶∞‡ßã‡¶™‡¶ø‡ßü‡¶æ‡¶® ‡¶≠‡¶æ‡¶∑‡¶æ‡¶∞ ‡¶ü‡ßá‡¶ï‡ßç‡¶∏‡¶ü ‡¶•‡¶æ‡¶ï‡¶≤‡ßá ‡¶∏‡ßá‡¶ó‡ßÅ‡¶≤‡ßã ‡¶†‡¶ø‡¶ï‡¶†‡¶æ‡¶ï ‡¶™‡ßú‡¶§‡ßá ‡¶è‡¶á ‡¶è‡¶®‡¶ï‡ßã‡¶°‡¶ø‡¶Ç ‡¶¶‡¶∞‡¶ï‡¶æ‡¶∞ ‡¶π‡ßü‡•§ ‡¶®‡¶æ‡¶π‡¶≤‡ßá error ‡¶¶‡¶ø‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá‡•§\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e47e3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['v1', 'v2']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4c787bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1baa09b",
   "metadata": {},
   "source": [
    "Rename :\n",
    "v1        ‚Üí ‡¶Ø‡ßá‡¶ü‡¶æ label (ham/spam)\n",
    "v2        ‚Üí ‡¶Ø‡ßá‡¶ü‡¶æ message/text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17c3bbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['label', 'message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6289dbaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6833192e",
   "metadata": {},
   "source": [
    "Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "320b362c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)  # Remove any nulls (if present)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116ee611",
   "metadata": {},
   "source": [
    " Preprocess the Data\n",
    "Convert labels to numbers:\n",
    "\n",
    "Yes, absolutely! You can preprocess **categorical labels** like `ham/spam` using multiple encoding techniques. Let‚Äôs compare the three main approaches and show how you can apply them.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ 1. Using `.map()` (Best for Binary Labels ‚Äì Recommended Here)\n",
    "\n",
    "```python\n",
    "df['label_num'] = df['label'].map({'ham': 0, 'spam': 1})\n",
    "```\n",
    "\n",
    "* üîπ Simple and direct\n",
    "* üîπ Works great for binary classification\n",
    "* üîπ Output: single column with 0 or 1\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ 2. Using **LabelEncoder** (Works for multiple classes)\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['label_num'] = le.fit_transform(df['label'])\n",
    "```\n",
    "\n",
    "* üîπ Useful if there are more than 2 labels\n",
    "* üîπ `ham` ‚Üí 0, `spam` ‚Üí 1 (but automatically assigned)\n",
    "* üîπ Not ideal if you want to control label encoding manually\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ 3. Using **OneHotEncoder** (NOT needed for target variable in classification)\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(sparse=False, drop='first')  # drop='first' avoids dummy variable trap\n",
    "encoded = ohe.fit_transform(df[['label']])\n",
    "```\n",
    "\n",
    "* üîπ Converts into **two columns**: one for each class\n",
    "* üîπ Useful when the target is multi-class and you want to treat each class as separate binary output (for multi-label classification or neural nets)\n",
    "* ‚ùå Not recommended for binary classification with scikit-learn estimators like `LogisticRegression`\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ So What to Use Here?\n",
    "\n",
    "Since this is a **binary classification problem (spam or ham)**, the best and cleanest approach is:\n",
    "\n",
    "```python\n",
    "df['label'] = df['label'].map({'ham': 0, 'spam': 1})\n",
    "```\n",
    "\n",
    "You **don‚Äôt need OneHotEncoder** unless your model requires it (e.g., in some neural networks or multi-label tasks).\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "366ee845",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label_num'] = df['label'].map({'ham': 0, 'spam': 1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14051c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  label_num\n",
       "0   ham  Go until jurong point, crazy.. Available only ...          0\n",
       "1   ham                      Ok lar... Joking wif u oni...          0\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...          1\n",
       "3   ham  U dun say so early hor... U c already then say...          0\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...          0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f61dc71",
   "metadata": {},
   "source": [
    "Feature Engineering (Text ‚Üí Numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cad6512",
   "metadata": {},
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(df['message'])\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca7f03b",
   "metadata": {},
   "source": [
    "it's better process:=>  Clean the text  then use => Convert Text to Numbers (TF-IDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda74a42",
   "metadata": {},
   "source": [
    "import string\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "\n",
    "\n",
    "def clean_text(text):  // Whose job is to clear a message\n",
    "\n",
    "    text = text.lower() // all text convert in lower case\n",
    "\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) //Delete the  punctuation and special character\n",
    "    (like .,!?@#$%) =>  Hello! How are you? ‚Üí Hello How are you\n",
    "\n",
    "    words = text.split() //'i love coding' ‚Üí ['i', 'love', 'coding']\n",
    "\n",
    "    filtered_words = [ps.stem(w) for w in words if w not in stop_words]//Stopwords remove  (like: 'the', 'is', 'in', 'and' ) and then  stemming=> convert in  root form: 'running' ‚Üí 'run' ,'loved' ‚Üí 'love' , 'easily' ‚Üí 'easili'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return ' '.join(filtered_words) //put together  like : \"Hi there!!! I loved the meeting, it was fantastic.\" -> \"hi love meet fantast\"\n",
    "\n",
    "\n",
    "df['cleaned'] = df['message'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92226bb5",
   "metadata": {},
   "source": [
    " Clean the text "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e840dd",
   "metadata": {},
   "source": [
    "Natural Language Toolkit: using nltk we do on human language and  natural language like Tokenization\t‡¶¨‡¶æ‡¶ï‡ßç‡¶Ø‡¶ï‡ßá ‡¶∂‡¶¨‡ßç‡¶¶‡ßá ‡¶≠‡¶æ‡¶ó ‡¶ï‡¶∞‡¶æ\n",
    "Stopwords Removal\t‚Äúthe‚Äù, ‚Äúis‚Äù, ‚Äúin‚Äù ‡¶è‡¶∞ ‡¶Æ‡¶§‡ßã ‡¶∏‡¶æ‡¶ß‡¶æ‡¶∞‡¶£ ‡¶Ö‡¶•‡¶ö ‡¶Ö‡¶™‡ßç‡¶∞‡ßü‡ßã‡¶ú‡¶®‡ßÄ‡ßü ‡¶∂‡¶¨‡ßç‡¶¶ ‡¶¨‡¶æ‡¶¶ ‡¶¶‡ßá‡¶ì‡ßü‡¶æ\n",
    "Stemming\t‡¶∂‡¶¨‡ßç‡¶¶‡¶ï‡ßá ‡¶Æ‡ßÇ‡¶≤ ‡¶∞‡ßÇ‡¶™‡ßá ‡¶Ü‡¶®‡¶æ (e.g. ‚Äúrunning‚Äù ‚Üí ‚Äúrun‚Äù)\n",
    "Lemmatization\t‡¶∂‡¶¨‡ßç‡¶¶‡ßá‡¶∞ dictionary ‡¶∞‡ßÇ‡¶™‡ßá ‡¶Ü‡¶®‡¶æ\n",
    "POS Tagging\t‡¶ï‡ßã‡¶® ‡¶∂‡¶¨‡ßç‡¶¶‡¶ü‡¶æ noun, verb, adjective ‡¶§‡¶æ ‡¶∂‡¶®‡¶æ‡¶ï‡ßç‡¶§ ‡¶ï‡¶∞‡¶æ\n",
    "Text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c818a01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71c62855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    words = text.split()\n",
    "    filtered_words = [ps.stem(w) for w in words if w not in stop_words] #here w is all words and we are removing stop words\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "df['cleaned'] = df['message'].apply(clean_text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e42c2fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>label_num</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "      <td>go jurong point crazi avail bugi n great world...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "      <td>ok lar joke wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "      <td>free entri 2 wkli comp win fa cup final tkt 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "      <td>u dun say earli hor u c alreadi say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "      <td>nah dont think goe usf live around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  label_num  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...          0   \n",
       "1   ham                      Ok lar... Joking wif u oni...          0   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...          1   \n",
       "3   ham  U dun say so early hor... U c already then say...          0   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...          0   \n",
       "\n",
       "                                             cleaned  \n",
       "0  go jurong point crazi avail bugi n great world...  \n",
       "1                              ok lar joke wif u oni  \n",
       "2  free entri 2 wkli comp win fa cup final tkt 21...  \n",
       "3                u dun say earli hor u c alreadi say  \n",
       "4          nah dont think goe usf live around though  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ca52cd",
   "metadata": {},
   "source": [
    "Step 3: Convert Text to Numbers (TF-IDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5933fb0e",
   "metadata": {},
   "source": [
    "**TF-IDF vector ‡¶Æ‡¶æ‡¶®‡ßá ‡¶ï‡ßÄ?** ‚Äî ‡¶è‡¶ü‡¶æ NLP ‡¶¨‡¶æ Text Classification\n",
    "\n",
    "## ‚úÖ TF-IDF ‡¶Æ‡¶æ‡¶®‡ßá ‡¶ï‡ßÄ?\n",
    "\n",
    "**TF-IDF** ‡¶è‡¶∞ ‡¶™‡ßÇ‡¶∞‡ßç‡¶£‡¶∞‡ßÇ‡¶™:\n",
    "\n",
    "```\n",
    "TF ‚Üí Term Frequency  \n",
    "IDF ‚Üí Inverse Document Frequency\n",
    "```\n",
    "\n",
    "‡¶è‡¶ü‡¶æ ‡¶è‡¶ï‡¶ü‡¶æ **text-to-number conversion technique** ‚Äî ‡¶Ø‡ßá‡¶ü‡¶æ ‡¶ï‡ßã‡¶®‡ßã **word-‡¶è‡¶∞ importance (‡¶ó‡ßÅ‡¶∞‡ßÅ‡¶§‡ßç‡¶¨)** calculate ‡¶ï‡¶∞‡ßá ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶æ message ‡¶¨‡¶æ document-‡¶è‡¶∞ ‡¶≠‡¶ø‡¶§‡¶∞‡ßá‡•§\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Main Goal:\n",
    "\n",
    "Text (like: \"Hello, this is spam message\") ‚Üí ‡¶ï‡ßá Machine ‡¶¨‡ßÅ‡¶ú‡¶¨‡ßá ‡¶®‡¶æ, ‡¶ï‡¶æ‡¶∞‡¶£ ‡¶ì‡¶ü‡¶æ string‡•§\n",
    "\n",
    "‡¶§‡¶æ‡¶á ‡¶§‡ßã‡¶Æ‡¶æ‡¶ï‡ßá ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶æ word ‡¶ï‡ßá **number/vector** ‡¶è ‡¶∞‡ßÇ‡¶™‡¶æ‡¶®‡ßç‡¶§‡¶∞ ‡¶ï‡¶∞‡¶§‡ßá ‡¶π‡¶¨‡ßá‡•§\n",
    "TF-IDF ‡¶†‡¶ø‡¶ï ‡¶∏‡ßá‡¶ü‡¶æ‡¶á ‡¶ï‡¶∞‡ßá ‚Äì ‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ ‡¶∂‡ßÅ‡¶ß‡ßÅ‡¶Æ‡¶æ‡¶§‡ßç‡¶∞ number ‡¶è ‡¶®‡¶æ, **importance ‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡ßü‡ßÄ weight** ‡¶¶‡ßá‡ßü‡•§\n",
    "\n",
    "---\n",
    "\n",
    "## üß† TF (Term Frequency) ‡¶Æ‡¶æ‡¶®‡ßá:\n",
    "\n",
    "‡¶è‡¶ï‡¶ü‡¶æ message-‡¶è‡¶∞ ‡¶≠‡¶ø‡¶§‡¶∞‡ßá ‡¶ï‡ßã‡¶®‡ßã word ‡¶ï‡¶§‡¶¨‡¶æ‡¶∞ ‡¶Ü‡¶õ‡ßá?\n",
    "\n",
    "### ‡¶â‡¶¶‡¶æ‡¶π‡¶∞‡¶£:\n",
    "\n",
    "Message: `\"You are very very good\"`\n",
    "\n",
    "* TF(\"very\") = 2\n",
    "* TF(\"you\") = 1\n",
    "\n",
    "---\n",
    "\n",
    "## üß† IDF (Inverse Document Frequency) ‡¶Æ‡¶æ‡¶®‡ßá:\n",
    "\n",
    "‡¶Ø‡ßá word ‡¶Ö‡¶®‡ßá‡¶ï ‡¶ó‡ßÅ‡¶≤‡ßã message-‡¶è common ‡¶Ü‡¶õ‡ßá (‡¶Ø‡ßá‡¶Æ‡¶®: \"is\", \"the\", \"you\"), ‡¶§‡¶æ‡¶¶‡ßá‡¶∞ ‡¶ó‡ßÅ‡¶∞‡ßÅ‡¶§‡ßç‡¶¨ ‡¶ï‡¶Æ‡•§\n",
    "\n",
    "‡¶Ü‡¶∞ ‡¶Ø‡ßá‡¶∏‡¶¨ word unique ‡¶¨‡¶æ rare (‡¶Ø‡ßá‡¶Æ‡¶®: \"winner\", \"free\", \"offer\") ‚Äî ‡¶§‡¶æ‡¶¶‡ßá‡¶∞ ‡¶ó‡ßÅ‡¶∞‡ßÅ‡¶§‡ßç‡¶¨ ‡¶¨‡ßá‡¶∂‡¶ø‡•§\n",
    "\n",
    "‡¶è‡¶ü‡¶æ‡¶á IDF‡•§\n",
    "\n",
    "---\n",
    "\n",
    "## üîÑ TF-IDF Formula:\n",
    "\n",
    "```\n",
    "TF-IDF(word) = TF(word) √ó IDF(word)\n",
    "```\n",
    "\n",
    "‡¶Ö‡¶∞‡ßç‡¶•‡¶æ‡ßé, ‡¶è‡¶ï‡¶ü‡¶æ‡¶∞ message-‡¶è ‡¶ï‡¶§‡¶¨‡¶æ‡¶∞ ‡¶è‡¶∏‡ßá‡¶õ‡ßá (TF) √ó ‡¶ï‡¶§‡¶ü‡¶æ unique ‡¶∏‡ßá‡¶á word ‡¶™‡ßÅ‡¶∞‡ßã dataset-‡¶è (IDF)\n",
    "\n",
    "---\n",
    "\n",
    "## üì¶ Final Output:\n",
    "\n",
    "‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶æ message ‚Üí ‡¶è‡¶ï‡¶ü‡¶æ **TF-IDF vector**\n",
    "‡¶Ø‡¶æ‡¶∞ ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶æ value ‚Üí ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶æ word-‡¶è‡¶∞ importance weight (0.0 ‡¶•‡ßá‡¶ï‡ßá 1.0 ‡¶è‡¶∞ ‡¶Æ‡¶§‡ßã)\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ ‡¶â‡¶¶‡¶æ‡¶π‡¶∞‡¶£ ‡¶¶‡¶ø‡ßü‡ßá ‡¶¨‡¶≤‡¶ø:\n",
    "\n",
    "‡¶ß‡¶∞‡ßã 3‡¶ü‡¶æ message ‡¶Ü‡¶õ‡ßá:\n",
    "\n",
    "1. \"Buy now\"\n",
    "2. \"Limited offer now\"\n",
    "3. \"Now or never\"\n",
    "\n",
    "‚Üí TF-IDF vectorizer ‡¶è ‡¶∏‡¶¨ word ‡¶ï‡ßá numeric ‡¶¨‡¶æ‡¶®‡¶ø‡ßü‡ßá ‡¶®‡¶ø‡¶ö‡ßá‡¶∞ ‡¶Æ‡¶§‡ßã ‡¶è‡¶ï‡¶ü‡¶æ matrix ‡¶¨‡¶æ‡¶®‡¶æ‡¶¨‡ßá:\n",
    "\n",
    "| Word    | Msg 1 | Msg 2 | Msg 3 |\n",
    "| ------- | ----- | ----- | ----- |\n",
    "| buy     | 1.2   | 0     | 0     |\n",
    "| limited | 0     | 1.5   | 0     |\n",
    "| offer   | 0     | 1.2   | 0     |\n",
    "| now     | 1.0   | 0.8   | 0.7   |\n",
    "| or      | 0     | 0     | 1.0   |\n",
    "| never   | 0     | 0     | 1.5   |\n",
    "\n",
    "(‡¶∏‡¶Ç‡¶ñ‡ßç‡¶Ø‡¶æ‡¶ó‡ßÅ‡¶≤‡ßã ‡¶â‡¶¶‡¶æ‡¶π‡¶∞‡¶£‡¶Æ‡¶æ‡¶§‡ßç‡¶∞)\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ ‡¶ï‡ßá‡¶® TF-IDF ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶¨‡ßã?\n",
    "\n",
    "* Word importance ‡¶¨‡ßã‡¶ù‡ßá (common word ‡¶¨‡¶æ‡¶¶ ‡¶¶‡ßá‡ßü)\n",
    "* Sparse matrix ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡ßá (memory efficient)\n",
    "* Model train ‡¶ï‡¶∞‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø perfect numeric format ‡¶¶‡ßá‡ßü\n",
    "\n",
    "---\n",
    "\n",
    "## üîÅ Bonus Tip:\n",
    "\n",
    "* **`TfidfVectorizer()`** ‡¶è‡¶á ‡¶ï‡¶æ‡¶ú‡¶ü‡¶æ ‡¶∏‡¶¨ ‡¶®‡¶ø‡¶ú‡ßá‡¶∞ ‡¶•‡ßá‡¶ï‡ßá‡¶á ‡¶ï‡¶∞‡ßá‡•§\n",
    "* ‡¶§‡ßÅ‡¶Æ‡¶ø ‡¶∂‡ßÅ‡¶ß‡ßÅ `.fit_transform(text)` ‡¶¶‡¶æ‡¶ì, ‡¶¨‡¶æ‡¶ï‡¶ø ‡¶∏‡¶¨ ‡¶ì manage ‡¶ï‡¶∞‡ßá ‡¶®‡ßá‡ßü‡•§\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4395de51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform(df['cleaned'])\n",
    "y = df['label_num']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df70815",
   "metadata": {},
   "source": [
    "Step 4: Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79bb77ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba43a1a",
   "metadata": {},
   "source": [
    "Step 5: Train Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12715a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"‚ñ∏\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"‚ñæ\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b9ac7d",
   "metadata": {},
   "source": [
    "Step 6: Predict & Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d276100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9426008968609866\n",
      "\n",
      "Confusion Matrix:\n",
      " [[961   4]\n",
      " [ 60  90]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       965\n",
      "           1       0.96      0.60      0.74       150\n",
      "\n",
      "    accuracy                           0.94      1115\n",
      "   macro avg       0.95      0.80      0.85      1115\n",
      "weighted avg       0.94      0.94      0.94      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b952d1b2",
   "metadata": {},
   "source": [
    "‡¶§‡ßã‡¶Æ‡¶æ‡¶∞ confusion matrix ‡¶Ü‡¶∞ classification report ‡¶¶‡ßá‡¶ñ‡ßá ‡¶Ü‡¶Æ‡¶ø ‡¶™‡ßÅ‡¶∞‡ßã performance ‡¶¨‡ßÅ‡¶ù‡¶ø‡ßü‡ßá ‡¶¶‡¶ø‡¶ö‡ßç‡¶õ‡¶ø ‚Äî ‡¶è‡¶ï‡¶¶‡¶Æ ‡¶∏‡¶π‡¶ú‡¶≠‡¶æ‡¶¨‡ßá‡•§\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Step-by-step Analysis:\n",
    "\n",
    "### üìå Confusion Matrix:\n",
    "\n",
    "```\n",
    "[[961   4]\n",
    " [ 60  90]]\n",
    "```\n",
    "\n",
    "‡¶è‡¶ü‡¶æ‡¶∞ ‡¶Æ‡¶æ‡¶®‡ßá:\n",
    "\n",
    "|                     | **Predicted Ham (0)** | **Predicted Spam (1)** |\n",
    "| ------------------- | --------------------- | ---------------------- |\n",
    "| **Actual Ham (0)**  | 961 (‚úÖ TN)            | 4 (‚ùå FP)               |\n",
    "| **Actual Spam (1)** | 60 (‚ùå FN)             | 90 (‚úÖ TP)              |\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Metrics Breakdown:\n",
    "\n",
    "| Metric        | Ham (0)        | Spam (1)   |\n",
    "| ------------- | -------------- | ---------- |\n",
    "| **Precision** | 0.94           | 0.96       |\n",
    "| **Recall**    | 1.00 (perfect) | 0.60 (low) |\n",
    "| **F1-score**  | 0.97           | 0.74       |\n",
    "\n",
    "---\n",
    "\n",
    "## üîç ‡¶¨‡ßã‡¶ù‡¶æ‡¶∞ ‡¶™‡¶¶‡ßç‡¶ß‡¶§‡¶ø:\n",
    "\n",
    "### üîπ False Positive (FP = 4)\n",
    "\n",
    "* **Model ‡¶¨‡¶≤‡ßá‡¶õ‡ßá Spam**, ‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ ‡¶Ü‡¶∏‡¶≤‡ßá ‡¶∏‡ßá‡¶ü‡¶æ **Ham** ‡¶õ‡¶ø‡¶≤\n",
    "* ‡¶è‡¶∞ ‡¶Æ‡¶æ‡¶®‡ßá: ‡¶ï‡¶æ‡¶ï‡ßá ‡¶Æ‡ßá‡¶∏‡ßá‡¶ú ‡¶™‡¶æ‡¶†‡¶æ‡¶®‡ßã ‡¶Ø‡¶æ‡ßü, ‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶¨‡¶≤‡ßá ‡¶¶‡ßá‡ßü ‡¶è‡¶ü‡¶æ spam ‚Äî annoying!\n",
    "\n",
    "### üî∏ False Negative (FN = 60)\n",
    "\n",
    "* **Model ‡¶¨‡¶≤‡ßá‡¶õ‡ßá Ham**, ‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ ‡¶Ü‡¶∏‡¶≤‡ßá ‡¶∏‡ßá‡¶ü‡¶æ **Spam** ‡¶õ‡¶ø‡¶≤\n",
    "* ‡¶è‡¶∞ ‡¶Æ‡¶æ‡¶®‡ßá: **‡¶Æ‡¶°‡ßá‡¶≤ spam detect ‡¶ï‡¶∞‡¶§‡ßá ‡¶¨‡ßç‡¶Ø‡¶∞‡ßç‡¶• ‡¶π‡ßü‡ßá‡¶õ‡ßá** ‚Äî ‡¶è‡¶ü‡¶æ dangerous! ‡¶ï‡¶æ‡¶∞‡¶£ user ‡¶∏‡ßç‡¶™‡ßç‡¶Ø‡¶æ‡¶Æ ‡¶Æ‡ßá‡¶∏‡ßá‡¶ú ‡¶™‡¶æ‡¶¨‡ßá‡•§\n",
    "\n",
    "---\n",
    "\n",
    "## üìâ Main Problem:\n",
    "\n",
    "* **Recall for class 1 (spam)** = 0.60 ‚Üí ‡¶ï‡¶Æ\n",
    "  ‡¶Æ‡¶æ‡¶®‡ßá: ‡¶Æ‡ßã‡¶ü 150 ‡¶ü‡¶æ ‡¶∏‡ßç‡¶™‡ßç‡¶Ø‡¶æ‡¶Æ ‡¶Æ‡ßá‡¶∏‡ßá‡¶ú ‡¶õ‡¶ø‡¶≤, ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶†‡¶ø‡¶ï‡¶Æ‡¶§‡ßã ‡¶ß‡¶∞‡¶§‡ßá ‡¶™‡ßá‡¶∞‡ßá‡¶õ‡ßá ‡¶Æ‡¶æ‡¶§‡ßç‡¶∞ **90 ‡¶ü‡¶æ** ‚Üí 60 ‡¶Æ‡¶ø‡¶∏ ‡¶ï‡¶∞‡ßá‡¶õ‡ßá‡•§\n",
    "\n",
    "---\n",
    "\n",
    "## üìà Accuracy ‡¶¶‡ßá‡¶ñ‡ßá ‡¶¨‡ßã‡¶ï‡¶æ ‡¶π‡¶ì‡ßü‡¶æ ‡¶Ø‡¶æ‡¶¨‡ßá ‡¶®‡¶æ\n",
    "\n",
    "Accuracy = **94.2%**, ‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ ‡¶∏‡ßá‡¶ü‡¶æ misleading, ‡¶ï‡¶æ‡¶∞‡¶£:\n",
    "\n",
    "* ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶≠‡¶æ‡¶≤‡ßã‡¶≠‡¶æ‡¶¨‡ßá **ham detect** ‡¶ï‡¶∞‡¶õ‡ßá\n",
    "* ‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ **spam detect** ‡¶ï‡¶∞‡¶§‡ßá ‡¶ï‡¶Æ ‡¶™‡¶æ‡¶∞‡¶õ‡ßá (recall = 0.60)\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ ‡¶ï‡¶∞‡¶£‡ßÄ‡ßü (Suggestions):\n",
    "\n",
    "1. **Class imbalance fix ‡¶ï‡¶∞‡ßã** (ham ‡¶¨‡ßá‡¶∂‡¶ø ‚Üí spam ‡¶ï‡¶Æ)\n",
    "\n",
    "   * Use: `SMOTE`, `RandomOversampler`, `class_weight='balanced'`\n",
    "2. **Preprocessing improve ‡¶ï‡¶∞‡ßã**\n",
    "\n",
    "   * Noise reduce + stemming/lemmatization ‡¶†‡¶ø‡¶ï ‡¶ï‡¶∞‡ßã\n",
    "3. **Threshold tuning** ‡¶ï‡¶∞‡ßã (probability cut-off)\n",
    "4. **Try better models** ‚Üí Naive Bayes / XGBoost / Ensemble\n",
    "\n",
    "---\n",
    "\n",
    "## üîö Summary (Banglay):\n",
    "\n",
    "| ‡¶¨‡¶ø‡¶∑‡ßü              | ‡¶¨‡¶ø‡¶∂‡ßç‡¶≤‡ßá‡¶∑‡¶£             |\n",
    "| ----------------- | -------------------- |\n",
    "| **Ham**           | ‡¶ñ‡ßÅ‡¶¨ ‡¶≠‡¶æ‡¶≤‡ßã‡¶≠‡¶æ‡¶¨‡ßá ‡¶ß‡¶∞‡ßá‡¶õ‡ßá   |\n",
    "| **Spam**          | ‡¶Ö‡¶®‡ßá‡¶ï‡¶ó‡ßÅ‡¶≤‡ßã ‡¶Æ‡¶ø‡¶∏ ‡¶ï‡¶∞‡ßá‡¶õ‡ßá   |\n",
    "| **FP (4)**        | ‡¶ñ‡ßÅ‡¶¨ ‡¶ï‡¶Æ, that's good  |\n",
    "| **FN (60)**       | ‡¶¨‡ßá‡¶∂‡¶ø, ‡¶è‡¶ü‡¶æ ‡¶¨‡¶ø‡¶™‡¶ú‡ßç‡¶ú‡¶®‡¶ï   |\n",
    "| **Recall (Spam)** | 0.60 ‚Üí Improve ‡¶¶‡¶∞‡¶ï‡¶æ‡¶∞ |\n",
    "\n",
    "---\n",
    "\n",
    "üëâ ‡¶§‡ßÅ‡¶Æ‡¶ø ‡¶ö‡¶æ‡¶á‡¶≤‡ßá ‡¶Ü‡¶Æ‡¶ø next step ‡¶è class imbalance ‡¶¨‡¶æ threshold tuning ‡¶¶‡ßá‡¶ñ‡¶æ‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡¶ø ‚Äî ‡¶¨‡¶≤‡¶≤‡ßá‡¶á ‡¶π‡¶¨‡ßá‡•§\n",
    "\n",
    "‡¶§‡ßã‡¶Æ‡¶æ‡¶∞ turn ‚úãüôÇ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d649dc",
   "metadata": {},
   "source": [
    "‡¶Ö‡¶∏‡¶æ‡¶ß‡¶æ‡¶∞‡¶£ ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶®! ‡¶§‡ßÅ‡¶Æ‡¶ø ‡¶¨‡¶≤‡¶õ‡ßã ‚Äî\n",
    "**‚Äú‡¶∏‡¶¨‡¶ï‡¶ø‡¶õ‡ßÅ ‡¶†‡¶ø‡¶ï ‡¶•‡¶æ‡¶ï‡¶≤‡ßá, ‡¶Ö‡¶∞‡ßç‡¶•‡¶æ‡ßé ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶Ø‡¶¶‡¶ø ‡¶è‡¶ï‡¶ü‡¶æ‡¶ì ‡¶≠‡ßÅ‡¶≤ ‡¶®‡¶æ ‡¶ï‡¶∞‡¶§‡ßã, ‡¶§‡¶æ‡¶π‡¶≤‡ßá Confusion Matrix ‡¶ï‡ßá‡¶Æ‡¶® ‡¶π‡¶§‡ßã?‚Äù**\n",
    "\n",
    "‡¶ö‡¶≤ ‡¶è‡¶ï‡¶¶‡¶Æ ‡¶ï‡ßç‡¶≤‡¶ø‡ßü‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßá ‡¶¶‡ßá‡¶ñ‡¶ø üëá\n",
    "\n",
    "---\n",
    "\n",
    "## üü® ‡¶¨‡¶∞‡ßç‡¶§‡¶Æ‡¶æ‡¶® ‡¶Æ‡ßá‡¶ü‡ßç‡¶∞‡¶ø‡¶ï‡ßç‡¶∏:\n",
    "\n",
    "```\n",
    "[[961   4]\n",
    " [ 60  90]]\n",
    "```\n",
    "\n",
    "‡¶è‡¶ñ‡¶æ‡¶®‡ßá ‡¶¶‡ßá‡¶ñ‡¶æ ‡¶Ø‡¶æ‡¶ö‡ßç‡¶õ‡ßá:\n",
    "\n",
    "* ‚úÖ ‡¶†‡¶ø‡¶ï ‡¶¨‡¶≤‡ßá‡¶õ‡ßá: 961 + 90 = **1051 ‡¶¨‡¶æ‡¶∞**\n",
    "* ‚ùå ‡¶≠‡ßÅ‡¶≤ ‡¶¨‡¶≤‡ßá‡¶õ‡ßá: 4 + 60 = **64 ‡¶¨‡¶æ‡¶∞**\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ ‡¶Ø‡¶¶‡¶ø ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶è‡¶ï‡¶¶‡¶Æ Perfect ‡¶π‡¶§‡ßã...\n",
    "\n",
    "‡¶Æ‡¶æ‡¶®‡ßá ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶∏‡¶¨‡¶ó‡ßÅ‡¶≤‡ßã ‡¶Æ‡ßá‡¶∏‡ßá‡¶ú **‡¶è‡¶ï‡¶¶‡¶Æ ‡¶∏‡¶†‡¶ø‡¶ï‡¶≠‡¶æ‡¶¨‡ßá** \"ham\" ‡¶¨‡¶æ \"spam\" ‡¶¨‡¶≤‡ßá ‡¶¶‡¶ø‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡¶§‡ßã ‚Äî\n",
    "‡¶§‡¶æ‡¶π‡¶≤‡ßá confusion matrix ‡¶π‡¶§‡ßã:\n",
    "\n",
    "```\n",
    "[[965   0]\n",
    " [  0 150]]\n",
    "```\n",
    "\n",
    "### ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ñ‡ßç‡¶Ø‡¶æ:\n",
    "\n",
    "* ‡¶∏‡¶¨ **ham (total 965)** ‚Üí ‡¶†‡¶ø‡¶ï‡¶≠‡¶æ‡¶¨‡ßá ham ‡¶π‡¶ø‡¶∏‡ßá‡¶¨‡ßá ‡¶ß‡¶∞‡¶§‡ßã\n",
    "* ‡¶∏‡¶¨ **spam (total 150)** ‚Üí ‡¶†‡¶ø‡¶ï‡¶≠‡¶æ‡¶¨‡ßá spam ‡¶π‡¶ø‡¶∏‡ßá‡¶¨‡ßá ‡¶ß‡¶∞‡¶§‡ßã\n",
    "* ‡¶§‡¶æ‡¶á **False Positive (FP) = 0**\n",
    "* **False Negative (FN) = 0**\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ ‡¶§‡¶ñ‡¶® Accuracy ‡¶π‡¶§‡ßã:\n",
    "\n",
    "```python\n",
    "accuracy = (TN + TP) / total\n",
    "         = (965 + 150) / 1115\n",
    "         = 1115 / 1115\n",
    "         = 1.0 ‚úÖ\n",
    "```\n",
    "\n",
    "### üî• ‡¶Ö‡¶∞‡ßç‡¶•‡¶æ‡ßé Accuracy = **100%**\n",
    "\n",
    "---\n",
    "\n",
    "## üîÅ Recap Table:\n",
    "\n",
    "| Actual / Predicted | Predicted: Ham | Predicted: Spam |\n",
    "| ------------------ | -------------- | --------------- |\n",
    "| Actual: Ham        | ‚úÖ TN = 965     | ‚ùå FP = 0        |\n",
    "| Actual: Spam       | ‚ùå FN = 0       | ‚úÖ TP = 150      |\n",
    "\n",
    "---\n",
    "\n",
    "## üìå Conclusion:\n",
    "\n",
    "‡¶Ø‡¶¶‡¶ø ‡¶Æ‡¶°‡ßá‡¶≤ ‡¶è‡¶ï‡¶ü‡¶æ‡¶ì ‡¶≠‡ßÅ‡¶≤ ‡¶®‡¶æ ‡¶ï‡¶∞‡¶§, ‡¶§‡¶æ‡¶π‡¶≤‡ßá:\n",
    "\n",
    "* `Confusion Matrix: [[965, 0], [0, 150]]`\n",
    "* `Accuracy: 1.0 (100%)`\n",
    "* `Precision, Recall, F1-score ‚Üí ‡¶∏‡¶¨ 1.00`\n",
    "\n",
    "---\n",
    "\n",
    "‡¶§‡ßÅ‡¶Æ‡¶ø ‡¶Ø‡¶¶‡¶ø ‡¶ö‡¶æ‡¶ì ‡¶Ü‡¶Æ‡¶ø ‡¶è‡¶á‡¶ü‡¶æ ‡¶è‡¶ï‡¶ü‡¶æ **graph ‡¶¨‡¶æ table ‡¶Ü‡¶ï‡¶æ‡¶∞‡ßá image** ‡¶¨‡¶æ‡¶®‡¶ø‡ßü‡ßá ‡¶¶‡ßá‡¶ñ‡¶æ‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡¶ø‡•§\n",
    "\n",
    "‡¶§‡¶æ‡¶π‡¶≤‡ßá Visual ‡¶Ü‡¶∞‡¶ì ‡¶ï‡ßç‡¶≤‡¶ø‡ßü‡¶æ‡¶∞ ‡¶π‡¶¨‡ßá üìä‚úÖ\n",
    "‡¶¨‡¶≤‡¶≤‡ßá‡¶á ‡¶ï‡¶∞‡ßá ‡¶¶‡¶ø‡¶ö‡ßç‡¶õ‡¶ø!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5709aa",
   "metadata": {},
   "source": [
    "\n",
    "‡¶§‡ßã‡¶Æ‡¶æ‡¶∞ Classification Report ‡¶¶‡ßá‡¶ñ‡ßá ‡¶¨‡ßã‡¶ù‡¶æ‡¶á ‡¶Ø‡¶æ‡¶ö‡ßç‡¶õ‡ßá ‡¶Æ‡¶°‡ßá‡¶≤ **spam ‡¶ó‡ßÅ‡¶≤‡ßã‡¶ï‡ßá (label = 1)** ‡¶†‡¶ø‡¶ï‡¶Æ‡¶§‡ßã ‡¶ß‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡¶õ‡ßá ‡¶®‡¶æ ‚Äî recall ‡¶ï‡¶Æ (0.60), ‡¶Ö‡¶∞‡ßç‡¶•‡¶æ‡ßé **‡¶Ö‡¶®‡ßá‡¶ï spam ‡¶Æ‡¶ø‡¶∏ ‡¶ï‡¶∞‡¶õ‡ßá**‡•§\n",
    "\n",
    "‡¶ö‡¶≤‡ßã ‡¶§‡ßã‡¶Æ‡¶æ‡¶∞ suggestions ‡¶ó‡ßÅ‡¶≤‡ßã‡¶∞ ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶ü‡¶ø‡¶∞ ‡¶¨‡ßç‡¶Ø‡¶æ‡¶ñ‡ßç‡¶Ø‡¶æ ‡¶¶‡¶ø‡¶á + ‡¶ï‡¶ø ‡¶ï‡¶∞‡¶£‡ßÄ‡ßü ‡¶§‡¶æ ‡¶∏‡ßç‡¶ü‡ßá‡¶™ ‡¶¨‡¶æ‡¶á ‡¶∏‡ßç‡¶ü‡ßá‡¶™ ‡¶¨‡ßã‡¶ù‡¶æ‡¶á:\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ 1. **Class Imbalance Fix ‡¶ï‡¶∞‡¶æ**\n",
    "\n",
    "### ‡¶ï‡¶æ‡¶∞‡¶£:\n",
    "\n",
    "* Ham = 965\n",
    "* Spam = 150\n",
    "  ‚Üí ‡¶Ö‡¶®‡ßá‡¶ï‡¶ü‡¶æ Imbalance ‚Üí ‡¶Æ‡¶°‡ßá‡¶≤ \"ham\" ‡¶¨‡ßá‡¶∂‡¶ø ‡¶∂‡ßá‡¶ñ‡ßá, spam ‡¶è ‡¶≠‡ßÅ‡¶≤ ‡¶ï‡¶∞‡ßá‡•§\n",
    "\n",
    "### ‡¶∏‡¶Æ‡¶æ‡¶ß‡¶æ‡¶®:\n",
    "\n",
    "```python\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X, y)\n",
    "```\n",
    "\n",
    "‡¶Ö‡¶•‡¶¨‡¶æ:\n",
    "\n",
    "```python\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler()\n",
    "X_res, y_res = ros.fit_resample(X, y)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ 2. **Preprocessing Improve ‡¶ï‡¶∞‡¶æ (Stemming, Lemmatization)**\n",
    "\n",
    "### ‡¶ï‡¶æ‡¶∞‡¶£:\n",
    "\n",
    "* \"loved\", \"loving\", \"loves\" ‚Üí ‡¶∏‡¶¨ ‡¶è‡¶ï‡¶á ‡¶Ö‡¶∞‡ßç‡¶•, ‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ ‡¶≠‡¶ø‡¶®‡ßç‡¶® ‡¶ü‡ßã‡¶ï‡ßá‡¶®‡•§\n",
    "\n",
    "### ‡¶∏‡¶Æ‡¶æ‡¶ß‡¶æ‡¶®:\n",
    "\n",
    "```python\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    words = text.split()\n",
    "    filtered = [lemmatizer.lemmatize(w) for w in words if w not in stop_words]\n",
    "    return ' '.join(filtered)\n",
    "```\n",
    "\n",
    "‡¶è‡¶ü‡¶æ stemming ‡¶•‡ßá‡¶ï‡ßá‡¶ì better ‡¶π‡ßü ‡¶Ö‡¶®‡ßá‡¶ï ‡¶∏‡¶Æ‡ßü‡•§\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ 3. **Threshold Tuning (Cutoff)**\n",
    "\n",
    "### ‡¶ï‡¶æ‡¶∞‡¶£:\n",
    "\n",
    "By default:\n",
    "\n",
    "```python\n",
    "y_pred = model.predict(X_test) ‚Üí threshold = 0.5\n",
    "```\n",
    "\n",
    "‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ ‡¶§‡ßÅ‡¶Æ‡¶ø ‡¶ö‡¶æ‡¶á‡¶≤‡ßá:\n",
    "\n",
    "```python\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "y_pred_custom = (y_proba > 0.3).astype(int)  # Custom threshold\n",
    "```\n",
    "\n",
    "### ‡¶≤‡¶æ‡¶≠?\n",
    "\n",
    "* ‡¶§‡ßÅ‡¶Æ‡¶ø **spam ‡¶ß‡¶∞‡¶æ‡¶∞ sensitivity ‡¶¨‡¶æ‡ßú‡¶æ‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßã**\n",
    "* Recall improve ‡¶π‡¶¨‡ßá\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ 4. **Better Model ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶æ**\n",
    "\n",
    "### Try:\n",
    "\n",
    "* `MultinomialNB` ‚Üí Text ‡¶è‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶ñ‡ßÅ‡¶¨‡¶á ‡¶≠‡¶æ‡¶≤‡ßã\n",
    "* `XGBoost` ‚Üí Powerful Ensemble model\n",
    "* `RandomForestClassifier` ‚Üí Robust, stable\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ 5. **class\\_weight='balanced' ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶æ**\n",
    "\n",
    "‡¶Ø‡¶¶‡¶ø LogisticRegression ‡¶¨‡¶æ DecisionTree ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßã:\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "```\n",
    "\n",
    "‡¶è‡¶§‡ßá ‡¶Æ‡¶°‡ßá‡¶≤ imbalance ‡¶®‡¶ø‡¶ú‡ßá ‡¶¨‡ßÅ‡¶ù‡ßá ‡¶®‡ßá‡ßü‡•§\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ ‡¶Ö‡¶§‡¶ø‡¶∞‡¶ø‡¶ï‡ßç‡¶§ Tips:\n",
    "\n",
    "| Technique           | Impact               |\n",
    "| ------------------- | -------------------- |\n",
    "| TF-IDF + Lemmatizer | Noise ‡¶ï‡¶Æ‡¶æ‡ßü           |\n",
    "| SMOTE / ROS         | Recall ‡¶¨‡¶æ‡ßú‡¶æ‡ßü         |\n",
    "| Naive Bayes         | Text data-friendly   |\n",
    "| Custom threshold    | False Negatives ‡¶ï‡¶Æ‡¶æ‡ßü |\n",
    "| Ensemble (Voting)   | Accuracy + Stability |\n",
    "\n",
    "---\n",
    "\n",
    "## ‡¶Ø‡¶¶‡¶ø ‡¶ö‡¶æ‡¶ì:\n",
    "\n",
    "‡¶Ü‡¶Æ‡¶ø ‡¶§‡ßã‡¶Æ‡¶æ‡¶∞ ‡¶™‡ßÅ‡¶∞‡ßã pipeline (cleaning ‚Üí oversampling ‚Üí model ‚Üí evaluation)\n",
    "‡¶è‡¶ï‡¶ü‡¶æ final version ‡¶π‡¶ø‡¶∏‡ßá‡¶¨‡ßá ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡ßá ‡¶¶‡¶ø‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡¶ø ‚Äì ‡¶∏‡¶¨ ‡¶∏‡ßá‡¶ü‡¶ø‡¶Ç‡¶∏ ‡¶∏‡¶π‡•§\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e68c6c",
   "metadata": {},
   "source": [
    "Recall for class (ham)  is 1.00  it good"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352b5e9a",
   "metadata": {},
   "source": [
    "Yes ‚úÖ ‚Äî **Recall for class 0 (ham)** being **1.00** means:\n",
    "\n",
    "> ‚ö†Ô∏è Your model has **perfectly identified all ham messages** ‚Äî no **False Positives (FP)**.\n",
    "\n",
    "---\n",
    "\n",
    "### üîç Let‚Äôs break this down:\n",
    "\n",
    "Your confusion matrix:\n",
    "\n",
    "```\n",
    "              Predicted\n",
    "              Ham    Spam\n",
    "Actual Ham   [961     4]   ‚Üí Total 965 ham\n",
    "Actual Spam  [60     90]   ‚Üí Total 150 spam\n",
    "```\n",
    "\n",
    "* **True Negative (TN) = 961** ‚Üí ham correctly predicted as ham\n",
    "* **False Positive (FP) = 4** ‚Üí ham wrongly predicted as spam\n",
    "* **Recall = TN / (TN + FP)** ‚Üí but in binary classification, recall is for positive class (usually class=1)\n",
    "\n",
    "So when we talk about recall for **class 0 (ham)**:\n",
    "\n",
    "$$\n",
    "\\text{Recall}_{ham} = \\frac{TN}{TN + FP} = \\frac{961}{961 + 4} = 0.996 ‚â† 1.00\n",
    "$$\n",
    "\n",
    "**BUT**, wait! Actually, that's **specificity**, not recall.\n",
    "\n",
    "In multiclass/binary `classification_report` from sklearn:\n",
    "\n",
    "* **Recall for class 0** means:\n",
    "\n",
    "  $$\n",
    "  \\text{Recall}_{class\\_0} = \\frac{\\text{True class 0 predicted as class 0}}{\\text{All actual class 0}}\n",
    "  = \\frac{961}{961 + 4} = 0.996\n",
    "  $$\n",
    "\n",
    "So, the 1.00 recall means your model predicted **all ham messages correctly** (no **False Negatives** for ham), which matches if `FN = 0`.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Final Verdict:\n",
    "\n",
    "* Yes, recall of **1.00 for ham** is **very good** üëç\n",
    "* But the real issue is:\n",
    "  üî¥ **Recall for spam (class 1) is 0.60** ‚Üí your model is missing 40% of spam.\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Your Goal:\n",
    "\n",
    "If you‚Äôre building a **Spam Detector**, missing spam is **dangerous** ‚Üí try to improve recall for **class 1 (spam)**.\n",
    "\n",
    "---\n",
    "\n",
    "Want help boosting **spam recall** (class 1)?\n",
    "I can adjust your pipeline to do that with:\n",
    "\n",
    "* SMOTE / Oversampling\n",
    "* Threshold tuning\n",
    "* Better model\n",
    "\n",
    "Let me know and I‚Äôll code it for you üöÄ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde733a2",
   "metadata": {},
   "source": [
    "Great question! Let‚Äôs break it down clearly:\n",
    "\n",
    "---\n",
    "\n",
    "### üîç **What is SMOTE?**\n",
    "\n",
    "**SMOTE** stands for **Synthetic Minority Oversampling Technique**.\n",
    "\n",
    "It's a technique to **balance class imbalance** in datasets by **creating synthetic examples** of the **minority class** (e.g., \"spam\" in your case).\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ö†Ô∏è **Why do we need SMOTE?**\n",
    "\n",
    "In your spam detection dataset:\n",
    "\n",
    "* **Ham (class 0)** = 87%\n",
    "* **Spam (class 1)** = 13%\n",
    "\n",
    "This is a **class imbalance problem**.\n",
    "\n",
    "If you train a model directly, it may:\n",
    "\n",
    "* **Overfit to ham**\n",
    "* **Ignore spam**\n",
    "* Have **high accuracy** but **low recall for spam**\n",
    "\n",
    "For example:\n",
    "\n",
    "```python\n",
    "Accuracy: 95%\n",
    "Recall for spam: 60% ‚ùå (bad)\n",
    "```\n",
    "\n",
    "You **miss 40% of spam**, which is **dangerous**.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ **When to use SMOTE?**\n",
    "\n",
    "Use SMOTE **before training** your model when:\n",
    "\n",
    "1. You have **imbalanced data**\n",
    "2. You care about **recall for the minority class** (e.g., spam detection, fraud, disease)\n",
    "3. You want to **improve performance** for the rare class\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ **How to use it in your project?**\n",
    "\n",
    "Here‚Äôs your code:\n",
    "\n",
    "```python\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X, y)\n",
    "```\n",
    "\n",
    "* `X` = features (TF-IDF vectors of messages)\n",
    "* `y` = labels (0 = ham, 1 = spam)\n",
    "* `X_res`, `y_res` = balanced dataset (equal number of ham and spam)\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ What does this do?\n",
    "\n",
    "Let‚Äôs say:\n",
    "\n",
    "* Original data: 4000 ham, 600 spam\n",
    "* After SMOTE: 4000 ham, **4000 synthetic spam**\n",
    "\n",
    "Now train your model on `X_res`, `y_res` ‚Üí it becomes **fairer to spam**.\n",
    "\n",
    "---\n",
    "\n",
    "### üìà Benefit\n",
    "\n",
    "You get:\n",
    "\n",
    "* **Better recall for spam**\n",
    "* **Balanced model performance**\n",
    "* **Less bias toward ham**\n",
    "\n",
    "---\n",
    "\n",
    "### üöÄ Bonus: Full Example\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# 1. Split original data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2. Apply SMOTE on training data only\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "# 3. Train\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# 4. Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "Do you want me to:\n",
    "‚úÖ Integrate this into your **full spam detection pipeline**\n",
    "‚úÖ and improve spam recall?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede717ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
